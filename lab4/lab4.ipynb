{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 4: The General EM algorithm\n",
        "\n",
        "> The goal of the EM algorithm is to find maximum likelihood solutions for models having latent variables. [Bishop, Section 4.3]\n",
        "\n",
        "During last week we implemented a special case of the EM algorithm for Gaussian Mixture Models. This week, we will focus on the general case of the EM algorithm which will allow us to find maximum likelihood solutions for any models having latent variables.\n",
        "\n",
        "To motivate the EM algorithm, calculating and maximizing the log-likelihood function for the incomplete data is often hard and does not have an analytical solution. You can see this by working out the likelihood for mixture of Gausians discussed in Lab3. \n",
        "\n",
        "Suppose we have a set of observations $\\{x_1, \\ldots, x_N\\}$. We can represent this data by an $N \\times D$ matrix $X$. Similiary the corresponding latent variables \\{z_1, \\ldots, z_N\\} which are one-hot-representations of the cluster assignments are denoted with an $N \\times K$ matrix $Z$. We assume that observations are drawn independently from the same distribution. Hence the likelihood for the incomplete data is given by\n",
        "$$p(X| \\mu, \\Sigma) = \\prod_{n=1}^N \\sum_{k=1}^K \\pi_k \\mathcal{N}(x_n \\mid \\mu_k, \\Sigma_k).$$\n",
        "The $\\log$ in the log-likelihood will appear before the sum over the components, making it hard to optimize the above expression. Oftentimes, calculating the complete log-likelihood is significantly easier, which is again the case for the likelihood for Mixture of Gaussians\n",
        "$$p(X, Z| \\mu, \\Sigma) = \\prod_{n=1}^N \\prod_{k=1}^N \\pi^{z_{nk}}\\mathcal{N}(x_n \\mid \\mu_k, \\Sigma_k)^{z_{nk}},$$\n",
        "where we do not enounter the same problem as with the likelihood for incomplete data. Please, verify the above expressions as an exercise. \n",
        "\n",
        "However, as we want to maximize the likelihood function for the incomplete data, how are these two likelihoods linked to each other? This will become clear in Exercise 4. \n",
        "\n",
        "However, in order to achieve this, we need a way to quantify the distance between arbitrary two probability distributions. Let's use the KL divergence for this purpose. \n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "duuUpCNKSpQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KL-divergence\n",
        "\n",
        "For discussing the general EM algorithm we will need a way to measure how one distribution $p$ is different from a second distribution $q$. [KL-divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) is one of the most widespread ways to quantify this. We will encounter this divergence during next labs and project 1 focused on Variational Autoencoders as well. \n",
        "\n",
        "For distributions $p$ and $q$ of continuous r.v.'s, the *Kullback-Leibler divergence* (KL-divergence) is defined as\n",
        "$$KL(p || q) = \\int p(x)\\log\\frac{p(x)}{q(x)} dx.$$\n",
        "\n",
        "Now, we will verify that this is indeed a good way to measure the distance between two distributions.\n",
        "\n",
        "(Note that the notation we are using follows Bishop)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Md7n2_UVSpQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 0. (reminder from the lecture) Prove that KL divergence between arbitrary two distributions is non-negative\n",
        "\n",
        "a) Show that $\\log(x)$ is a concave function,\n",
        "\n",
        "b) State Jensen's inequality,\n",
        "\n",
        "c) Combining a) and b) show that the KL divergence is non-negative with equality iff. the two distributions are equal."
      ],
      "metadata": {
        "collapsed": false,
        "id": "FR0EUmMYSpQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1. Connecting KL divergence to MLE\n",
        "\n",
        "Show that minimizing the KL-divergence is equivalent to maximizing the log-likelihood function."
      ],
      "metadata": {
        "collapsed": false,
        "id": "3Ry1JTFWSpQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2. KL divergence between multivariate Gaussian distributions.\n",
        "\n",
        "Let $p_1(x \\mid \\mu_1, \\sigma_1^2), p_2(x \\mid \\mu_2, \\sigma_2^2)$ be two univariate Gaussian distributions.\n",
        "\n",
        "a) Calculate the entropy of $p_1$. \n",
        "\n",
        "a) Calculate the KL divergence between $p_1$ and $p_2$\n",
        "\n",
        "b) Use `torch.distributions` to plot $KL(p_1 || p_2)$ as a function of $\\mu_1$ and $\\sigma_1$, while keeping $\\mu_2 = 0$ and $\\sigma_2 = 1$ fixed.\n",
        "\n",
        "c) Is KL between two Gaussian distributions symmetric?\n",
        "\n",
        "d) (Optional) Does the triangle inequality hold?\n",
        "\n",
        "e) (Optional) Derive the same results for general multivariate Gaussian distributions. "
      ],
      "metadata": {
        "collapsed": false,
        "id": "COacR2W8SpQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3. Forward vs Reverse KL\n",
        "\n",
        "Look up the term forward and reverse KL in Bishop or on the internet and explain the difference.\n",
        "\n",
        "Explain the mode-seeking and mode-covering upon fitting a unimodal to a multimodal distribution."
      ],
      "metadata": {
        "collapsed": false,
        "id": "-b60LqWmSpQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4. A lower bound on the likelihood function.\n",
        "\n",
        "(Bishop, Exercise 9.24) Consider a probabilistic model in which we collectively denote all of the observed variables by $X$ and all of the hidden variables by $Z$.\n",
        " The joint distribution $p(X, Z|\\theta)$ is governed by a set of parameters denoted $\\theta$. Our goal is to maximize\n",
        "the likelihood function that is given by\n",
        "\n",
        "$$p(X \\mid \\theta) = \\sum_Z p(X, Z \\mid \\theta)$$\n",
        "\n",
        "Let $q(Z)$ be an arbitrary distribution defied over the latent variables $Z$.\n",
        "\n",
        "a) Show that the following decomposition holds\n",
        "$$\\ln p(X \\mid \\theta) = \\mathcal{L}(q, \\theta) + KL(q || p),$$\n",
        "where\n",
        "$$\\mathcal{L}(q, \\theta) = \\sum_Z q(Z)\\ln\\frac{p(X, Z \\mid \\theta)}{q(Z)}$$\n",
        "and\n",
        "$$KL(q || p) = - \\sum_Z q(Z) \\ln \\frac{p(Z \\mid X, \\theta)}{q(Z)}$$\n",
        "\n",
        "b) Explain why is $\\mathcal{L}$ a lower bound on $\\ln p(X \\mid \\theta)$.\n",
        "\n",
        "c) Explain why do we care in the context of the EM algorithm. Is maximizing a lower bound on an objective helpful in order to maximize the objective itself?"
      ],
      "metadata": {
        "collapsed": false,
        "id": "2XV1GSoDSpQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional Exercises\n",
        "\n",
        "(Bishop, Exercise 9.25)\n",
        "(Bishop, Exercise 9.4)\n",
        "Can you implement EM for a mixture of Bernoulli distributions?\n",
        "How to approximate KL-divergence using finite samples for any two probability distributions?"
      ],
      "metadata": {
        "collapsed": false,
        "id": "AxTAFDbQSpQJ"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}