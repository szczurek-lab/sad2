{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5789b909",
   "metadata": {},
   "source": [
    "# Markov Chain Monte Chocolate... wait, what?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac23e3a0",
   "metadata": {},
   "source": [
    "# 0. Estimate the value of $\\pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca22153",
   "metadata": {},
   "source": [
    "One way to estimate the value of $\\pi$ is to use the Monte Carlo method. The basic idea is to generate random points in a square and use the ratio of points inside a quarter circle to the total number of points to estimate the value of $\\pi$. \n",
    "You can checkout the gist here: https://www.youtube.com/shorts/DUxvw3_cISo. \n",
    "\n",
    "1. Import the random module in Python.\n",
    "2. Generate $n$ random pairs of $x$ and $y$ coordinates between $0$ and $1$. These coordinates will represent points in a unit square. \n",
    "3. Determine how many of the points fall inside the unit circle, which is defined as the set of points that are less than or equal to 1 unit away from the origin (0, 0).\n",
    "4. Calculate an estimate for $\\pi$ by multiplying the ratio of the number of points inside the circle to the total number of points by 4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46642b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C'mon, code sth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8d5903",
   "metadata": {},
   "source": [
    "# 1. Chocolate problems\n",
    "\n",
    "In the file chocolate.csv you have a dataset with ratings of 1700 chocolate bars. The rating system is as follows:\n",
    "\n",
    "- 5= Elite (Transcending beyond the ordinary limits)\n",
    "- 4= Premium (Superior flavor development, character and style)\n",
    "- 3= Satisfactory(3.0) to praiseworthy(3.75) (well made with special qualities)\n",
    "- 2= Disappointing (Passable but contains at least one significant flaw)\n",
    "- 1= Unpleasant (mostly unpalatable)\n",
    "\n",
    "We’re interested in the probability, that a chocolate is tasty. To check this, we will estimate the proportions of tasty chocolate bars in our dataset. We’ll assume that a chocolate bar is tasty if it’s rating is at least $2$.\n",
    "\n",
    "Assume that the rating for each chocolate bar is idependent. A random chocolate bar is tasty with probability $θ$. It follows that the number of tasty chocolate bars follows a Binomial distribution $Bin(n,θ)$, where n is the number of inspected bars.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f20843",
   "metadata": {},
   "source": [
    "## 1.1 Reminder on MLE:\n",
    "\n",
    "The MLE for $θ$ is $x/n$, where $x$ is the number of tasty chocolate bars. This is very intuitive: to estimate the proportion of good chocolate bars, we simply compute the proportion from the data.\n",
    "\n",
    "**Your tasks**\n",
    "- Estimate θ on the full dataset.\n",
    "- Suppose that in our sample we have chocolate bars number 126, 1412, 989 and 623. Compute the MLE from this sample.\n",
    "\n",
    "Overall, vast majority of chocolate bars are tasty. However, when we restricted our analysis to only four observations, we got very different results! Also, they’re not very credbile, because they’re inferred from just 4 chocolate bars. Bayesian analysis allows us to deal with this situation, by using so-called prior information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694db8c4",
   "metadata": {},
   "source": [
    "## 1.2 Reminder on MAP\n",
    "\n",
    "Even without any dataset, we know that more often than not chocolate is tasty. This is our prior knowledge about chocolate. Buying $4$ chocolate bars and finding out that $3$ are disgusting wouldn’t change our belief about chocolate in general - rather, we would only conclude that some of the brands are not that good. Intuitively, we know that a sample of $4$ chocolate bars is not enough to say anything about all chocolate - there is considerable amount of uncertainity in our results.\n",
    "\n",
    "In the Bayesian approach, we treat the parameter $\\theta$ as a random variable with some distribution of our choice. The randomness represents our uncertainity about the true value of $\\theta$. As we will see, this has several advantages, among others:\n",
    "\n",
    "- We can incorporate our prior knowledge,\n",
    "- Small samples won’t lead us to wrong conclusions as much as before,\n",
    "- We can quantify our uncertainity about the parameters.\n",
    "\n",
    "As before, we will assume that, if we know $\\theta$, the number of tasty chocolate bars follows a binomial distribution $Bin(n,\\theta)$. Now, however, we will assume that $\\theta$ is itself random, and follows a Beta distribution $Beta(a,b)$. The density of $\\theta$, $p(\\theta)$, is equal to\n",
    "\n",
    "$$p(\\theta) = \\frac{\\theta^{a-1}(1-\\theta)^{b-1}}{B(a, b)}.$$\n",
    "\n",
    "Here, $B(a,b)$ is a special function, called the Beta function, and its purpose is to make $p(\\theta)$ integrate to $1$. The distribution $p(\\theta)$ is called the prior distribution. The parameters $a,b$ have a straightforward interpretation: they are the numbers of tasty and untasty chocolate bars in our prior knowledge. Their sum, $n=a+b$, represents the strength of our prior belief. The fraction $$m=a/(a+b)$$ represent our prior belief about the proportion of tasty chocolate bars. The parameter n represents the strength of our prior knowledge - in other words, the number of chocolate bars we have seen so far to make our opinion and their average tastiness. In yet other words, $n$ is equal to the number of chocolate bars that we would need to inspect to change our beliefs about chocolate tastiness. **Later we will use $n$ and $m$ to re-parametrize the prior. In this parametrization, the prior is $Beta(mn,(1−m)n)$**.\n",
    "\n",
    "The distribution of the number of tasty chocolate bars conditioned on $\\theta$ is denoted $p(x|\\theta)$. This is our binomial distribution. The marginal distribution of tasty chocolate bars, $p(x)$, is obtained by intergrating over $\\theta$:\n",
    "\n",
    "$$p(x) = \\int_{\\theta \\in [0, 1]} p(x | \\theta) p(\\theta) d\\theta.$$\n",
    "\n",
    "This density represents the overall probability of observing $x$ tasty chocolate bars, regardless on the parameter $\\theta$. It depends on the parameters $a$ and $b$.\n",
    "\n",
    "To this point, we’ve covered the prior knowledge and it’s influence on our beliefs about the number of tasty chocolate bars. What about our goal - the estimation of $\\theta$? In Bayesian approach, we’re interested in the posterior distribution of our parameters. The posterior distribution is the distribution of $\\theta$ conditioned on our observations, $p(\\theta|x)$. It measures how our beliefs about the values of $\\theta$ are influenced by the data. To get the posterior, we use the Bayes rule (hence the name of the approach):\n",
    "\n",
    "$$p(\\theta | x) = \\frac{p(x | \\theta) p(\\theta)}{p(x)} = \\frac{p(x|\\theta) p(\\theta)}{\\int_{\\theta \\in [0, 1]} p(x | \\theta) p(\\theta) d\\theta}.$$\n",
    "\n",
    "Note that $\\theta$ in the numerator is not the same as $\\theta$ in the denominator - the former is set by us, the latter is a variable under the integral.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Your tasks**\n",
    "\n",
    "Personally, I believe that 99% of chocolate bars are tasty, and you would need to show me 100 disgusting bars to change my beliefs. \n",
    "Interpret my beliefs in terms of the parameters of the prior Beta distribution. \n",
    "\n",
    "Check how my beliefs would change if you’d give me the bars number 126, 1412, 989 and 623 (check how many of these four are untasty and how many are tasty). What about all the 1700 bars? \n",
    "Plot the prior and the two posterior densities.\n",
    "\n",
    "Reminder:\n",
    "\n",
    "The posterior distribution is $Beta(a+X,b+N−X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d7296",
   "metadata": {},
   "source": [
    "## 1.3 Monte Carlo approach to Chocolate\n",
    "\n",
    "In reality, I’m not exactly sure how many bars I’d need to check to change my beliefs. However, I could say that this number is a random variable itself. This leads us to a hierarchical model, which has several “layers” of randomness. \n",
    "\n",
    "I’ve told you that I assume that 90% bars are tasty, and I’d need 20 bars to change my beliefs. This lead to $m=0.9$ and $n=20$. As I mentioned, in reality I’m not exactly sure if $n=20$ - maybe it’s 21 or 18? In fact, it’s reasonable to assume that m and n are random as well. This leads us to the notion of hierarchical models, which have multiple layers of randomness.\n",
    "\n",
    "As before, let $X$ be the number of tasty chocolate bars, and assume that $X∼Bin(n,θ)$ and $θ∼Beta(nm,n(m−1))$. This time, however, we’ll assume that $n$ and $m$ are random. It’s reasonable to assume that $n$ is from Gamma distribution (which is a bit similar to Poisson distribution, but continuous), and $m$ from Beta. The full specification of our model is as follows:\n",
    "\n",
    "\\begin{align}\n",
    "X & \\sim Bin(n, \\theta), \\\\\n",
    "\\theta & \\sim Beta(nm, n(1-m)), \\\\\n",
    "n & \\sim Gamma(s, r), \\\\\n",
    "m & \\sim Beta(\\mu, \\nu).\n",
    "\\end{align}\n",
    "\n",
    "The deterministic variables $s$, $r$, $\\mu$ and $\\nu$ are called hyperparameters, because they influence the parameter $\\theta$. The values of the hyperparameters represent our prior knowledge. **Our goal is to infer the posterior distributions of $\\theta$, $n$ and $m$.** This is, however, usually impossible. Instead, we’ll use the Monte Carlo approach to simulate the random parameters from the posterior distribution.\n",
    "\n",
    "There are many methods to sample from the posterior distributions, the most important being the Metropolis-Hastings algorithm and the Gibbs sampler. Today, we will tackle the Metropolis-Hastings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b72c47",
   "metadata": {},
   "source": [
    "### Implementation of Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab13a48",
   "metadata": {},
   "source": [
    "\n",
    "Again, the goal here is to to infer the posterior distributions of $\\theta$, $n$ and $m$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfbed5e",
   "metadata": {},
   "source": [
    "We want to estimate the posterior distributions of all three parameters: $\\theta$, $n$ and $m$. $n$ measures the influence of $m$ on $\\theta$. \n",
    "To obtain easily interpretable parameters for $Gamma(s, r)$, note that $Y \\sim Gamma(s, r)$, then\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{E}X &= s/r \\\\\n",
    "Var X & = s/r^2\n",
    "\\end{align}\n",
    "\n",
    "It follows that\n",
    "\n",
    "\\begin{align}\n",
    "s & = \\mathbb{E}^2 X / Var X \\\\\n",
    "r & = \\mathbb{E} X / Var X.\n",
    "\\end{align}\n",
    "\n",
    "Now, recall that n represents the strength of our prior knowledge (the number of chocolate bars we’d need to check to alter our beliefs). So, if we believe that our beliefs are worth about 20±10 chocolate bars, it’s reasonable to parametrize the prior by specifying\n",
    "\n",
    "\\begin{align}\n",
    "s & = 10^2 / 10^2 = 1 \\\\\n",
    "r & = 10 / 10^2 = 0.1.\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Remember about the restrictions for parameters (e.g. $n≥0$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa38799",
   "metadata": {},
   "source": [
    "Hint: you can use $torch.distributions$ here if you want, but it might be more convenient to use $scipy.stats$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10820e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom, gamma, beta\n",
    "\n",
    "choco = pd.read_csv('chocolate.csv')\n",
    "\n",
    "# Set the hyperparameters\n",
    "prior_n = 20\n",
    "prior_m = 0.9\n",
    "nu = 2\n",
    "mu = 4\n",
    "s = 1\n",
    "r = 0.1\n",
    "\n",
    "# Set the observed data\n",
    "N = len(choco) # number of tested chocolate bars\n",
    "X = sum(choco['Rating'] >= 2) # number of tasty bars (maybe you can tweak it and set your expectations higher?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95460ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the posterior distribution as a function of the parameters\n",
    "def posterior(n, m, theta):\n",
    "  # Compute the likelihood of the observed data\n",
    "  likelihood = ...\n",
    "  \n",
    "  # Compute the prior distribution of the parameters\n",
    "  prior_n = ...\n",
    "  prior_m = ...\n",
    "  prior_theta = ...\n",
    "  \n",
    "  # Return the product of the likelihood and the priors as the unnormalized posterior\n",
    "  return likelihood * prior_n * prior_m * prior_theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81d3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MCMC chain with a random state\n",
    "np.random.seed(1234)\n",
    "\n",
    "n = prior_n\n",
    "m = prior_m\n",
    "theta = np.random.beta(prior_n * prior_m, prior_n * (1 - prior_m))\n",
    "\n",
    "# Set the number of iterations for the MCMC algorithm\n",
    "num_iterations = 10000 \n",
    "\n",
    "# Define empty lists to store the samples from the posterior\n",
    "n_samples = []\n",
    "m_samples = []\n",
    "theta_samples = []\n",
    "\n",
    "# Run the MCMC algorithm\n",
    "for i in range(num_iterations):\n",
    "    # Propose new values for the parameters\n",
    "    # Hint: there are many ways to do this \n",
    "    # TODO\n",
    "    \n",
    "    # Compute the unnormalized posterior probability at the current state and the proposed state\n",
    "    # TODO\n",
    "    \n",
    "    # Compute the acceptance probability\n",
    "    # TODO\n",
    "    \n",
    "    # Sample a uniform random variable\n",
    "    # TODO\n",
    "\n",
    "    # If the random variable is less than the acceptance probability, move to the proposed state\n",
    "    # TODO\n",
    "    \n",
    "    # Save the current state in the samples\n",
    "    # TODO\n",
    "\n",
    "# Compute the posterior means of the samples\n",
    "n_mean = np.mean(n_samples)\n",
    "m_mean = np.mean(m_samples)\n",
    "theta_mean = np.mean(theta_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1b371",
   "metadata": {},
   "source": [
    "### Extensions\n",
    "\n",
    "- Implement burn in\n",
    "- Implement thinning out "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f928eb",
   "metadata": {},
   "source": [
    "## 1.4. MCMC diagnostics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca76a9",
   "metadata": {},
   "source": [
    "Valid inferences from sequences of MCMC samples are based on the assumption that the samples are derived from the true posterior distribution of interest. Theory guarantees this condition as the number of iterations approaches infinity. It is important, therefore, to determine the minimum number of samples required to ensure a reasonable approximation to the target posterior density. Unfortunately, no universal threshold exists across all problems, so convergence must be assessed independently each time MCMC estimation is performed. The procedures for verifying convergence are collectively known as convergence diagnostics. (see more here: https://pymcmc.readthedocs.io/en/latest/modelchecking.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a5cac4",
   "metadata": {},
   "source": [
    "### 1.4.1 Trace\n",
    "Plot a trace of the MCMC samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1ff22",
   "metadata": {},
   "source": [
    "### 1.4.2 Histogram\n",
    "Plot a histogram of the MCMC samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e594d",
   "metadata": {},
   "source": [
    "### 1.4.3 Autocorrelation\n",
    "\n",
    "Samples from MCMC algorithms are ususally autocorrelated, due partly to the inherent Markovian dependence structure. For now, we will study individual variables within a model. Plot the autocorrelation for the three inferred variables using $plt.acorr$ with parameter $maxlags$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff6e69",
   "metadata": {},
   "source": [
    "## HW \n",
    "\n",
    "After this lab, write an e-mail to your TA with \"[SAD2] Lab9\" as a title with:\n",
    "- The diagnostics plots (trace, histogram, and autocorrelation) for $\\theta$ (if you want with thinning out/burn in applied) and your comment on it - is it safe to infer from this chain? \n",
    "- What has the model learned about chocolate? Compare prior and posteriors on $m$, $n$.\n",
    "- Finally, explain the fif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb29ac84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
